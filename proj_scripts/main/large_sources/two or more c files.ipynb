{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import re\n",
    "import pickle\n",
    "from make import make_dir,recover_make,all_,comp_,clang_flags,make_proc,make_routine,mopt_routine\n",
    "from make import opt_bc,opt_routine,targ_routine,phony_routine,clean_routine,reg_name,select_groups\n",
    "opt_ = [\"-O%s\" %i for i in [0,1,2,3,'s','z']]\n",
    "\n",
    "clang_ =[\"-O%s\" %i for i in [0,1,2,3,'fast','s','z','g','4']]\n",
    "all_divide = r'all\\s*\\:\\s*'\n",
    "w_out_space_divide = r'(?<!\\\\)\\s+'\n",
    "name_divide = r'.+\\s*\\:\\s+.*\\.[cpx]{1,3}.*'\n",
    "cf_reg = r'\\.[cpCP]{1,3}'\n",
    "\n",
    "frame = pd.DataFrame(columns=opt_,index=clang_)\n",
    "absdir = \"./../../../../Unix_Source/\"\n",
    "initdir = os.getcwd()+'/'\n",
    "largedir = absdir+'unix_cmp'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estb_src(abs_ls):\n",
    "#     print(os.listdir())\n",
    "    for res in os.listdir('result/'):\n",
    "        tmp = pickle.load(open('result/'+res,'rb'))\n",
    "        abs_ls = abs_ls.difference(tmp)\n",
    "    return abs_ls\n",
    "\n",
    "def log_file(lines,name=initdir+'complex.comp'):\n",
    "    with open(name,'a+') as file:\n",
    "        for line in lines:\n",
    "            if line[-1]!='\\n':\n",
    "                file.write(line+'\\n')\n",
    "            else:\n",
    "                file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "os.chdir(largedir)\n",
    "to_do = os.listdir()\n",
    "os.chdir(initdir)\n",
    "print(to_do.__len__())\n",
    "to_do = list(estb_src(set(to_do)))\n",
    "print(to_do.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_cond(line,xs):\n",
    "    res = None\n",
    "    if all_.match(line):\n",
    "        for targ in re.split(w_out_space_divide,re.split(all_divide,line[:-1])[-1]):\n",
    "#             print(targ)\n",
    "            xs[targ] = {} \n",
    "        xs['text'].append(line)\n",
    "        res = xs\n",
    "    return res\n",
    "def cmp_cond(line,xs):\n",
    "    res = None\n",
    "    if comp_.match(line):\n",
    "        cmp = re.split(w_out_space_divide,line)[1:]\n",
    "        if cmp[0] == 'g++':\n",
    "            cmp[0] = 'clang++'\n",
    "        else:\n",
    "            cmp[0] = 'clang'\n",
    "        \n",
    "        tmp = [cmp[0],clang_flags,'-o']+cmp[cmp.index('-o')+2:]\n",
    "\n",
    "        \n",
    "        targ = cmp[cmp.index('-o')+1]\n",
    "        cmp = cmp[1:cmp.index('-o')]\n",
    "        for arg in cmp:\n",
    "            xs[targ][re.split(cf_reg,arg)[0]] = {'cmp':tmp,'opt':None,'abs_name':re.split(cf_reg,arg)[0],'c_name':arg}\n",
    "#         xs['text'].append('\\t\\t'+' '.join(tmp)+'\\n')\n",
    "#         print('\\t\\t'+' '.join(tmp)+'\\n')\n",
    "        res = xs\n",
    "    return res\n",
    "\n",
    "def name_cond(line,xs):\n",
    "    res = None\n",
    "    if reg_name.match(line):\n",
    "#         print(line)\n",
    "        res = xs\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(initdir)\n",
    "# pickle.dump(todo,open('comp1.init','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(initdir)\n",
    "recover_make(largedir,pickle.load(open('comp1.init','rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo = {} \n",
    "# for line,signa in select_groups(to_do,largedir)['comp']:\n",
    "#     todo[signa] = {'text':[],'exec':[],'target':{},'opts':[]}\n",
    "# make_routine(largedir,todo,[all_cond,cmp_cond,name_cond])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_existance(xs,exs,_str):\n",
    "    flag = False\n",
    "    len_ = exs.__len__()\n",
    "    exs.add(_str)\n",
    "    if  len_!=exs.__len__():\n",
    "        xs['text'].append(_str)\n",
    "        flag = True\n",
    "    else:\n",
    "        print('asd')\n",
    "\n",
    "    return flag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asd\n",
      "asd\n",
      "asd\n",
      "asd\n",
      "asd\n",
      "asd\n"
     ]
    }
   ],
   "source": [
    "todo = {} \n",
    "for line,signa in select_groups(to_do,largedir)['comp']:\n",
    "    todo[signa] = {'text':[],'opts':[]}\n",
    "make_routine(largedir,todo,[all_cond,cmp_cond,name_cond])\n",
    "\n",
    "for ult in todo:\n",
    "    _all = [todo[ult]['text'][0][:-1]]\n",
    "    arg_gp = list(filter(lambda x: (x!='text') and (x!='opts'),list(todo[ult])))\n",
    "    \n",
    "    for targ in arg_gp:\n",
    "        for arg in todo[ult][targ]:\n",
    "            name_ = todo[ult][targ][arg]['abs_name']\n",
    "            _all+=[name_+'.ll',name_+'.bc']\n",
    "    _all = ' '.join(_all) +'\\n'\n",
    "\n",
    "    todo[ult]['text'][0] = _all\n",
    "    todo[ult]['text'].insert(0,phony_routine)\n",
    "    \n",
    "    set_tmp = set()\n",
    "    for targ in arg_gp:\n",
    "        for arg in todo[ult][targ]:\n",
    "            c_name = todo[ult][targ][arg]['c_name']\n",
    "            a_name = todo[ult][targ][arg]['abs_name']\n",
    "            conf = todo[ult][targ][arg]['cmp']\n",
    "\n",
    "            check_existance(todo[ult],set_tmp,('{}: {}\\n'.format(a_name+'.ll',c_name)))\n",
    "            \n",
    "            check_existance(todo[ult],set_tmp,'\\t\\t{0} {1} -o {2} {3}\\n'.format(' '.join(conf[:conf.index('-o')])\n",
    "                                                          ,c_name,a_name+'.ll'\n",
    "                                                             ,' '.join(conf[conf.index('-o')+1:])))\n",
    "            \n",
    "\n",
    "\n",
    "            if check_existance(todo[ult],set_tmp,mopt_routine(a_name+'.ll',(a_name+'.bc'))):\n",
    "                todo[ult]['opts'].append(todo[ult]['text'].__len__()-1)\n",
    "    \n",
    "    for targ in arg_gp:\n",
    "#         print(' '.join(conf[:1]+conf[2:conf.index('-o')]))\n",
    "        targ_bc = ' '.join(list(map(lambda x:x+'.bc',list(todo[ult][targ]))))\n",
    "        todo[ult]['text'].append('{0}:{1}\\n\\t\\t{2} {3} -o {4} {5}\\n'.format(targ\n",
    "                                               ,targ_bc,' '.join(conf[:1]+conf[2:conf.index('-o')])\n",
    "                                               ,targ_bc,targ\n",
    "                                               ,' '.join(conf[conf.index('-o')+1:])))\n",
    "#         print(todo[ult]['text'][-1])\n",
    "    todo[ult]['text'].append(clean_routine(re.split(all_divide,_all)[1]))\n",
    "#     todo[ult]['text'] = list(set(todo[ult]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'14416 main\\n'\n",
      "b'14416 main\\n'\n",
      "b'14416 main\\n'\n",
      "b'14416 main\\n'\n",
      "b'14416 main\\n'\n",
      "b'14416 main\\n'\n",
      "b'37024 main\\n'\n",
      "b'41040 main\\n'\n",
      "b'41040 main\\n'\n",
      "b'41040 main\\n'\n",
      "b'41040 main\\n'\n",
      "b'41040 main\\n'\n",
      "b'34920 test\\n'\n",
      "b'35024 test\\n'\n",
      "b'35024 test\\n'\n",
      "b'35024 test\\n'\n",
      "b'35024 test\\n'\n",
      "b'35024 test\\n'\n",
      "b'18104 bwtcoder\\n'\n",
      "b'22200 bwtcoder\\n'\n",
      "b'26296 bwtcoder\\n'\n",
      "b'26296 bwtcoder\\n'\n",
      "b'26296 bwtcoder\\n'\n",
      "b'22200 bwtcoder\\n'\n",
      "b'19816 main\\n'\n",
      "b'19816 main\\n'\n",
      "b'19816 main\\n'\n",
      "b'19816 main\\n'\n",
      "b'19816 main\\n'\n",
      "b'19816 main\\n'\n",
      "b'13760 main\\n'\n",
      "b'13760 main\\n'\n",
      "b'13760 main\\n'\n",
      "b'13760 main\\n'\n",
      "b'13760 main\\n'\n",
      "b'13760 main\\n'\n",
      "b'40224 main\\n'\n",
      "b'40232 main\\n'\n",
      "b'40232 main\\n'\n",
      "b'40232 main\\n'\n",
      "b'40232 main\\n'\n",
      "b'40232 main\\n'\n",
      "b'13928 SMLMAIN\\n'\n",
      "b'13976 SMLMAIN\\n'\n",
      "b'13976 SMLMAIN\\n'\n",
      "b'13976 SMLMAIN\\n'\n",
      "b'13976 SMLMAIN\\n'\n",
      "b'13928 SMLMAIN\\n'\n",
      "b'34400 RopeStrings\\n'\n",
      "b'34448 RopeStrings\\n'\n",
      "b'34448 RopeStrings\\n'\n",
      "b'34448 RopeStrings\\n'\n",
      "b'34448 RopeStrings\\n'\n",
      "b'30352 RopeStrings\\n'\n",
      "b'24112 main\\n'\n",
      "b'24168 main\\n'\n",
      "b'24168 main\\n'\n",
      "b'24168 main\\n'\n",
      "b'24168 main\\n'\n",
      "b'24168 main\\n'\n",
      "b'13752 sortedarray\\n'\n",
      "b'13752 sortedarray\\n'\n",
      "b'17848 sortedarray\\n'\n",
      "b'17848 sortedarray\\n'\n",
      "b'17848 sortedarray\\n'\n",
      "b'13752 sortedarray\\n'\n",
      "b'20720 hcomp\\n'\n",
      "b'20672 hdecomp\\n'\n",
      "b'20440 hcomp\\n'\n",
      "b'20440 hdecomp\\n'\n",
      "b'20440 hcomp\\n'\n",
      "b'20440 hdecomp\\n'\n",
      "b'20440 hcomp\\n'\n",
      "b'20440 hdecomp\\n'\n",
      "b'20440 hcomp\\n'\n",
      "b'20440 hdecomp\\n'\n",
      "b'20440 hcomp\\n'\n",
      "b'20440 hdecomp\\n'\n",
      "b'14144 main\\n'\n",
      "b'14200 main\\n'\n",
      "b'14144 main\\n'\n",
      "b'14144 main\\n'\n",
      "b'14144 main\\n'\n",
      "b'14144 main\\n'\n",
      "b'18832 main\\n'\n",
      "b'18936 main\\n'\n",
      "b'18880 main\\n'\n",
      "b'18880 main\\n'\n",
      "b'18880 main\\n'\n",
      "b'14784 main\\n'\n",
      "b'13696 main\\n'\n",
      "b'13744 main\\n'\n",
      "b'13744 main\\n'\n",
      "b'13744 main\\n'\n",
      "b'13744 main\\n'\n",
      "b'13696 main\\n'\n",
      "b'406152 main\\n'\n",
      "b'426192 main\\n'\n",
      "b'426192 main\\n'\n",
      "b'426192 main\\n'\n",
      "b'426192 main\\n'\n",
      "b'422096 main\\n'\n",
      "b'34200 Main\\n'\n",
      "b'34256 Main\\n'\n",
      "b'34256 Main\\n'\n",
      "b'34256 Main\\n'\n",
      "b'34256 Main\\n'\n",
      "b'34256 Main\\n'\n"
     ]
    }
   ],
   "source": [
    "err = set()\n",
    "res_opt = {'-O0':{},'-O1':{},'-O2':{},'-O3':{},'-Os':{},'-Oz':{}}\n",
    "for ult in todo:\n",
    "    os.chdir(absdir+'unix_cmp')\n",
    "    dir_ = make_dir(\"{}/{}/\".format(ult,'source'))[0]\n",
    "    os.chdir(dir_)\n",
    "    for option in opt_:\n",
    "        for op in todo[ult]['opts']:  \n",
    "            _opt = (todo[ult]['text'][op])\n",
    "\n",
    "            tmp = _opt.split('\\n')[1]\n",
    "            tmp = re.split(w_out_space_divide,tmp)\n",
    "            tmp[2] = option\n",
    "            todo[ult]['text'][op] = '\\n'.join([_opt.split('\\n')[0],'\\t\\t'+' '.join(tmp)+'\\n'])\n",
    "        with open('Makefile','wt') as make_file:\n",
    "            for line in todo[ult]['text']:\n",
    "                make_file.write(line)    \n",
    "        make_proc(['make'],log_file,ult)\n",
    "        res = -1\n",
    "        try:\n",
    "            for targ in list(filter(lambda x: (x!='text') and (x!='opts'),list(todo[ult]))):\n",
    "                res =subprocess.check_output(\"wc -c {}\".format(targ), stderr=subprocess.STDOUT,\n",
    "                                                       shell=True)\n",
    "                res_opt[option][ult] = res\n",
    "                print(res)\n",
    "        except Exception:\n",
    "            err.add(ult)\n",
    "            print(ult,targ)\n",
    "\n",
    "        make_proc(['make','clean'],log_file,ult)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-O0': {'Huffman compression algorithm.': b'20672 hdecomp\\n'},\n",
       " '-O1': {'Huffman compression algorithm.': b'20440 hdecomp\\n'},\n",
       " '-O2': {'Huffman compression algorithm.': b'20440 hdecomp\\n'},\n",
       " '-O3': {'Huffman compression algorithm.': b'20440 hdecomp\\n'},\n",
       " '-Os': {'Huffman compression algorithm.': b'20440 hdecomp\\n'},\n",
       " '-Oz': {'Huffman compression algorithm.': b'20440 hdecomp\\n'}}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(initdir+'result/')\n",
    "# pickle.dump(res_opt,open('complex_file.result','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
